{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here\n",
                "\n",
                "It's recommended to use this notebook for exploration purposes."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from bs4 import BeautifulSoup\n",
                "import requests\n",
                "import time\n",
                "import sqlite3\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import pandas as pd\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "No se pudo obtener la página.\n"
                    ]
                }
            ],
            "source": [
                "# URL de la página que contiene la tabla\n",
                "resource_url = \"https://ycharts.com/companies/TSLA/revenues\"\n",
                "\n",
                "# Hacer la solicitud para obtener el contenido de la página\n",
                "response = requests.get(resource_url)\n",
                "\n",
                "# Verificar si la solicitud fue exitosa\n",
                "if response.status_code == 200:\n",
                "    # Analizar el contenido HTML con BeautifulSoup\n",
                "    soup = BeautifulSoup(response.text, 'html.parser')\n",
                "\n",
                "if '403 ERROR' in response:\n",
                "    headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.102 Safari/537.36'}\n",
                "    request = requests.get(url,headers=headers)\n",
                "    time.sleep(5)\n",
                "    response = request.text\n",
                "\n",
                "    # Encontrar la tabla en el HTML (puedes ajustar el selector según la estructura HTML de la página)\n",
                "    table = soup.find(\"table\")  # Encuentra la primera tabla en la página, si hay varias puedes especificar mejor el selector\n",
                "\n",
                "    # Extraer filas de la tabla\n",
                "    rows = []\n",
                "    for row in table.find_all(\"tr\"):\n",
                "        cells = [cell.get_text(strip=True) for cell in row.find_all([\"th\", \"td\"])]\n",
                "        rows.append(cells)\n",
                "\n",
                "    # Crear un DataFrame de pandas con los datos de la tabla\n",
                "    df = pd.DataFrame(rows[1:], columns=rows[0])  # La primera fila como encabezado\n",
                "    df.to_csv(\"revenue_data.csv\", index=False)  # Guardar el DataFrame como CSV\n",
                "    print(\"Archivo guardado como 'revenue_data.csv'\")\n",
                "else:\n",
                "    print(\"No se pudo obtener la página.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
